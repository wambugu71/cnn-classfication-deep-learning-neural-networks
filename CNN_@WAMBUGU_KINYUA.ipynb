{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7af0994",
   "metadata": {},
   "source": [
    "# CNN with tensorflow keras\n",
    "- In this tutorial we shall  Focus on how to create a neural network for  classification in keras.\n",
    "Here we shall focus  on training our model with image data  ie  for cats and dogs.\n",
    "- Ready to be taken through by ``@ wambugu kinyua.``\n",
    "Visit  my  github account for  more. \n",
    "> > > - [ ] __Click__ [Here](https://www.github.com/wambugu71) to visit my other projects.\n",
    "> > > - [ ] __email__ `kenliz1738@gmail.com`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decb9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as  pd\n",
    "import  numpy as  np \n",
    "import  matplotlib.pyplot  as  plt\n",
    "from tensorflow  import  keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers  import  Dense, MaxPooling2D, Conv2D, Flatten, BatchNormalization, Dropout\n",
    "from keras .preprocessing.image  import  ImageDataGenerator\n",
    "import  tensorflow as  tf\n",
    "from tensorflow.keras.optimizers.legacy import  Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7c61ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 images\n"
     ]
    }
   ],
   "source": [
    "#@wambugu kinyua Remove  corrupted image files\n",
    "import os\n",
    "num_skipped = 0\n",
    "for folder_name in (\"cats\", \"dogs\"):\n",
    "    folder_path = os.path.join(\"train_set\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(\"Deleted %d images\" % num_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a79171ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.ImageDataGenerator at 0x29613e7eb20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True,)\n",
    "train_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f9b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf3d36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1999 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#image geberation\n",
    "training_set= train_datagen.flow_from_directory(\"train_set/\", target_size= (224,224), class_mode=\"categorical\")\n",
    "test_set = test_datagen.flow_from_directory(\"test\", target_size=(224,224),class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597025f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 223, 223, 16)      208       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 223, 223, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 111, 111, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 111, 111, 16)      0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 111, 111, 32)      2080      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 111, 111, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 55, 55, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 55, 55, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 55, 55, 64)        8256      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 55, 55, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 27, 27, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 46656)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                466570    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 477,624\n",
      "Trainable params: 477,380\n",
      "Non-trainable params: 244\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,activation=\"relu\", kernel_size=2, input_shape=(224,224,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=64,padding=\"same\",kernel_size=2, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b1abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer = keras.optimizers.SGD(learning_rate=0.01), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "63/63 [==============================] - 106s 2s/step - loss: 0.2879 - accuracy: 0.5368 - val_loss: 0.2682 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "63/63 [==============================] - 101s 2s/step - loss: 0.2619 - accuracy: 0.5818 - val_loss: 0.3469 - val_accuracy: 0.5000\n",
      "Epoch 3/25\n",
      "15/63 [======>.......................] - ETA: 1:16 - loss: 0.2569 - accuracy: 0.6000"
     ]
    }
   ],
   "source": [
    "r = model.fit(training_set, epochs=25,steps_per_epoch=len(training_set), validation_steps=len(test_set), validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae4d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Wambugu_kinyua_model9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c203730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "import  matplotlib as mpl\n",
    "import  numpy as  np \n",
    "import seaborn as sns \n",
    "sns.set(style=\"darkgrid\")\n",
    "mpl.rcParams[\"figure.figsize\"]=[15,10]\n",
    "plt.plot(r.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(r.history[\"accuracy\"], label=\"accuraccy\")\n",
    "plt.legend()\n",
    "plt.title(\"Models accuracy vs loss performace\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f103a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.py             plot as plt\n",
    "import  matplotlib as mpl\n",
    "import  numpy as  np \n",
    "import seaborn as sns \n",
    "sns.set(style=\"darkgrid\")\n",
    "mpl.rcParams[\"figure.figsize\"]=[15,10]\n",
    "plt.plot(r.history[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(r.history[\"val_accuracy\"], label=\"accuraccy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644b7f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\"dogs_00152.jpg\", target_size=(224,224)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09870858",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img_array)\n",
    "score= predictions[0][0]\n",
    "print(f\"This image is {100 * (1 - score)}% cat and {100 * score}% dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a58577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "import matplotlib as  mpl \n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end\n",
    "* Keep credits please\n",
    "* For  more projects [visit](https://github.com/wambugu71)\n",
    "* Regards `Wambu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
